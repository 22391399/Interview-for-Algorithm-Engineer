# Stable Diffusion 绘画基础知识

## 1. Stable Diffusion 是什么
Stable Diffusion 是 2022 年发布的深度学习文本到图像生成模型。它主要用于根据文本的描述产生详细图像，尽管它也可以应用于其他任务，如内补绘制、外补绘制，以及在提示词指导下产生图生图的转变。

它是一种潜在扩散模型，由慕尼黑大学的 CompVis 研究团体开发的各种生成性人工神经网络之一。它是由初创公司 StabilityAI、CompVis 与 Runway 合作开发，并得到 EleutherAI 和 LAION 的支持。截至 2022 年 10 月，StabilityAI 筹集了 1.01 亿美元的资金。

Stable Diffusion 的源代码和模型权重已分别公开发布在 GitHub 和 Hugging Face，可以在大多数配备有适度 GPU 的电脑硬件上运行。而以前的专有文生图模型（如 DALL-E 和 Midjourney）只能通过云计算服务访问。

## 2. 模型分类
### 2.1 主模型（Checkpoint）
- 主模型（大模型）是 AI 绘画的基础，影响画面的整体风格。
- 主模型通常较大，一般有几 GB 到十几 GB。

### 2.2 文本嵌入（Embedding）
- Embedding 是指将自然语言文本（如句子或段落）转换为计算机可以理解的数值向量的过程。我们可以理解为打包了很多提示词进一个词。
- Embedding 的大小为几十 KB。
- Embedding 倾向于训练角色特征。

### 2.3 LoRA（Low-Rank Adaptation of Large Language Models）
- LoRA 是一种用于微调大模型的技术。LoRA 模型应用于修改图片局部或优化图片。
- LoRA 模型的大小通常为几百 MB。

### 2.4 超网络（Hypernetwork）
- Hypernetwork 用法和功能和 Embedding 类似，更适合训练风格，而不是特定具象的物体。
- Hypernetwork 的大小为几十 KB。

### 2.5 VAE
- 使用 VAE 可以优化画面颜色，有些 VAE 也会对画风产生影响。

## 3. 常见问题
### 3.1 网址打不开?
在维护/需要魔法。

### 3.2 安装目录找不到?
在桌面右键启动器——查看安装目录。

### 3.3 安装后找不到模型?
安装后需要手动刷新模型列表。

### 3.4 下载模型后画出来的图不好看?
1. 是否有触发词。
2. 是不是底模和 VAE 不一致。
3. 检查参数是否正确。

### 3.5 下载模型需要预留多少空间?
一个大模型在 3-8 GB，至少需要预留 50 GB 的空间。

## 4. ControlNet 
### 4.1 作用
让生成结果更可控。能够提取参考图中的重要信息，以一定权重影响生成图效果，可以用来控制角色动作、样貌、所处空间等等。

### 4.2 安装
- 在 StableDiffusion\extensions 中删除 controlnet 文件夹。
- 扩展 - 可下载 - 加载扩展列表 - 'ctrl+f' 在输入框里输入 ControlNet - 点击 install - 安装完成后返回已安装 - 点击应用更改并重载前端。

## 5. 提示词公式
- 质量词放在最前面。
- 其他元素根据重要性由前向后排列。
- 相关性比较高的词放在一起。
- 光照、镜头、风格、描述等。

## 6. 功能详解
### 6.1 采样迭代步数
决定图片细节质量，迭代步数越多，越详细，同时对显卡内存的消耗越大，建议数值在（20-30）。

### 6.2 提示词相关性
表示生成图像与你提示词的关联程度，常用数值在（7、 9、12）。

### 6.3 高清修复
用来放大你生成图片的分辨率，如果直接生成高分辨率图片，显存会溢出报错。
- 放大算法：重绘幅度高选择潜变量，重绘幅度低选择 R-ESRGAN 4x+ 或者 SwinIR 4x。
- 高清修复采样次数：对画面影响有限，建议数值在（0-30）。
- 重绘幅度：越高画面对比越强，也会与直接生成的图相差更远，常用数值 0.3~0.7。
- 放大倍率：等比例成倍放大图片；也可以指定放大的宽高数值。

### 6.4 生成批次和每批数量
- 生成批次：表示同样的配置让 AI 跑几次。
- 每批数量：表示 AI 每跑一次生成几张图，建议默认 1，多张图占用显存过多。

## 7. 采样是什么
SD 生成图像，会先生成一个完全随机的噪声，通过噪声预测估算图像噪声，再通过噪声预测进行去噪。去噪过程不断重复，最后得到一张干净的图像，去噪的过程称为采样，采样中使用的方法称为采样器或采样方法。

### 类型和特点
#### 老式 ODE 采样器
- Euler - 比较稳定。
- Heun - 会花费 Euler 双倍的时间。
- LMS
- PLMS 
- 50 步与 100 步的词结果差不多，高步数可能会更精细一些。

#### 祖先采样器
ccEuler a、DPM2 a、DPM+、+2S a、DPM++2S a、Karras、DPM++SDE、DPM++SDE Karras
- 一般带有字母 a 或 SDE 的采样器都是这一类，这类采样器每一步采样都会向图片添加新的噪声。如果想要稳定细化的图片就不要用祖先采样器。

#### Karras
- 带有 Karras 标签的采样器生成效果往往更好。

#### DPM/DPM++
- 效果：带++ 的 > 带2 的 > DPM。
- DPM adaptive：自适应步数，设定的步数会失效。

#### DDIM/PLMS
- SD 原始自带的采样器。
- DDIM 与祖先采样器一样，每一步采样都会向图片添加新的噪声。

#### Unipc
- 新发布的采样器，出图比较稳定，一般在 5-10 步就有不错的结果。
- 如果不能使用：设置 - 采样器参数 - Unipc 变体改为 bh2 - 保存设置 - 重启 WebUI。
- 如果列表没有这个采样器需在启动器 - 版本管理 - 选择最新的稳定版安装。

## 8. 权重控制规则
- 越靠前的关键词权重越大，() 为增加权重，[] 为减权重。
- 通常不会叠加高于三个括号。
- (tag) 提高权重 1.1 倍。
- ((tag)) 提高权重 1.21 倍，计算方式 1.1 * 1.1。
- [tag] 减少权重 1.1 倍。
- (tag:1.2) ≈ ((tag))。
- (tag:0.9) = [tag]。
- 快捷键为 ctrl + 上下箭头。

## 9. ControlNet 常见类型
### 9.1 invert 反向颜色
- 自己上传线稿时，如果线稿是白色背景黑色线条，则需要选择 invert 预处理器。
- 处理器选择 lineart。

### 9.2 canny 边缘检测
- 提取参考图中的边缘，能生成同样构图的画面，可自由决定细节，锁定细节。
- 如果参考图中有背景，主体比较容易被其他背景影响。

### 9.3 depth 深度检测
- 擅长捕捉画面中的空间关系，可生成同样构图的深度结构的图。
- 越近的物体会以越白的形式出现，越远的则越黑。

### 9.4 inpaint 局部重绘
- 和以图生图的图片重绘类似，但是会对整个画面进行重绘。

### 9.5 lineart 线稿
- 可以提取照片和插画的线稿，生成的图片比 canny 更加还原细节。

### 9.6 M-LSD 线段识别
- 直线捕捉，善于理解空间透视，适用于建筑和机械。
- 与 depth 相比可以有效去除建筑以外的物体。

### 9.7 softedge 软边缘
- 和 canny 类似，canny 边缘更加硬朗。HED 检测出的线条更像手绘，可以保留更多柔和的边缘细节。

### 9.8 tile 色块重绘
- 可以根据画面颜色理解画面内容，对画面进行重绘。
- 可以用于将模糊图片放大和色稿细化。

### 9.9 scribble 涂鸦
- 从参考图中提取黑白稿，然后生成新图。
- 可以上传或者自己在 ControlNet 中画一些涂鸦，让 AI 帮你细化。
- 示例：1 girl, full body, barn lantern。

### 9.10 normal 法线
- 还原图片中表面的凹凸起伏，擅长理解空间立体结构。
- Bae 包含远景，midas 只识别近景，可调节识别阈值。

### 9.11 openpose 姿势识别
- 可提取参考图中的人物动作，生成骨骼图。可控制多人人物动作。

### 9.12 seg 语义分割
- 把参考图中的元素进行类别拆分，用颜色标注物体的颜色。

### 9.13 shuffle 洗牌
- 可以提取原图中的风格和元素进行生成。

## 10. Midjourney 是什么？
《Midjourney》是一款 2022 年 3 月面世的 AI 绘画工具，创始人是 David Holz。只要输入想到的文字，就能通过人工智能产出相对应的图片，耗时只有大约一分钟。推出 beta 版后，这款搭载在 Discord 社区上的工具迅速成为讨论焦点。

## 11. 提示词规则
### 类别
#### 模型/风格切换
- `--v` 1~5：切换为相应的 Midjourney 模型，不推荐早期模型 1/2/3。
- `--niji` 留空，5：切换为相应的 Nijijourney 模型。
- `--style` 4a/4b/4c：切换为 4a/4b/4c 风格，Midjourney V4 模型下才能生效，不推荐使用。
- `--style` expressive/cute/scenic：切换为相应的风格，Nijijourney5 模型下才能生效。
- `--hd/test/testp` 留空：切换为相应的模型，早期模型 hd 和测试模型 test/testp，不推荐使用。
