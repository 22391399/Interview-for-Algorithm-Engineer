1.Stable diffusion是什么
Stable Diffusion是2022年发布的深度学习文本到图像生成模型。它主要用于根据文本的描述产生详细图像，尽管它也可以应用于其他任务，如内补绘制、外补绘制，以及在提示词指导下产生图生图的转变。
它是一种潜在扩散模型，由慕尼黑大学的CompVis研究团体开发的各种生成性人工神经网络之一。它是由初创公司StabilityAI、CompVis与Runway合作开发，并得到EleutherAI和LAION的支持。截至2022年10月，StabilityAI筹集了1.01亿美元的资金。
Stable Diffusion的源代码和模型权重已分别公开发布在GitHub和Hugging Face，可以在大多数配备有适度GPU的电脑硬件上运行。而以前的专有文生图模型（如DALL-E和Midjourney）只能通过云计算服务访问。

2.模型分类
2.1主模型（checkpoint）
●主模型（大模型）是Al绘画的基础，影响画面的整体风格。
●主模型通常较大，一般有几G到十几G。
2.2文本嵌入（Embedding）
●Embedding是指将自然语言文本（如句子或段落）转换为计算机可以理解的数值向量的过程。我们可以理解为打包了很多提示词进一个词
●embeding的大小为几十kb
●embeding倾向于训练角色特征
2.3LoRA（Low-Rank Adaptation of Large Language Models）
●LoRA是一种用于微调大模型的技术。LoRA模型应用于修改图片局部或优化图片
●LoRA模型的大小通常为几百Mb
2.4超网络（Hypernetwork）
●Hypernetwork用法和功能和embedding类似，更适合训练风格，而不是特定具象的物体。
●Hypernetwork的大小为几十kb 
2.5VAE
使用VAE可以优化画面颜色，有些VAE也会对画风产生影响

3.常见问题
3.1网址打不开?
在维护/需要魔法
3.2安装目录找不到?
在桌面右键启动器——查看安装目录
3.3安装后找不到模型?
安装后需要手动刷新模型列表
3.4下载模型后画出来的图不好看?
1.是否有触发词
2.是不是底模和VAE不一致
3.检查参数是否正确
3.5下载模型需要预留多少空间?

4.ControlNet 
4.1作用
让生成结果更可控。能够提取参考图中的重要信息，以一定权重影响生成图效果，可以用来控制角色动作、样貌、所处空间等等
4.2安装
●在StableDiffusion\extensions中删除controlnet文件夹
●扩展-可下载-加载扩展列表- 'ctrl+f'在输入框里输入ControlNet-点击install-安装完成后返回已安装-点击应用更改并重载前端

5.提示词公式
●质量词放在最前面
●其他元素根据重要性由前向后排列
●相关性比较高的词放在一起
●光照、镜头、风格、描述等

5.提示词公式
●质量词放在最前面
●其他元素根据重要性由前向后排列
●相关性比较高的词放在一起
●光照、镜头、风格、描述等

6.功能详解
6.1采样迭代步数
决定图片细节质量，迭代步数越多，越详细，同时对显卡内存的消耗越大，建议数值在（20-30）
6.2提示词相关性
表示生成图像与你提示词的关联程度，常用数值在（7、 9、12）
6.3高清修复
用来放大你生成图片的分辨率，如果直接生成高分辨率图片，显存会溢出报错
●放大算法：重绘幅度高选择潜变量，重绘幅度低选择R-ESRGAN 4x+或者Swin|R 4x
●高清修复采样次数：对画面影响有限，建议数值在（0-30）
●重绘幅度：越高画面对比越强，也会与直接生成的图相差更远，常用数值0.3~0.7
●放大倍率：等比例成倍放大图片;也可以指定放大的宽高数值
6.4生成批次和每批数量
生成批次：表示同样的配置让AI跑几次
每批数量：表示AI每跑一次生成几张图，建议默认1，多张图占用显存过多

7.采样是什么
SD生成图像，会先生成一个完全随机的噪声，通过噪声预测估算图像噪声，再通过噪声预测进行去噪
去噪过程不断重复，最后得到一张干净的图像，去噪的过程称为采样，采样中使用的方法称为采样器或采样方法

![image](https://github.com/WeThinkIn/Interview-for-Algorithm-Engineer/assets/171827073/9a742431-84fb-4305-a776-cde519b12136)

8.权重控制规则
●越靠前的关键词权重越大，()为增加权重，[]为减权重
●通常不会叠加高于三个括号
●(tag)提高权重1.1倍
●((ag))提高权重1.21倍
计算方式1.1*1.1
●[tag]减少权重1.1倍
●(Tag:1.2)≈((Tag)) 
●(Tag:0.9)=[Tag]
●快捷键为ctrl+上下箭头

9.ControlNet常见类型
9.1invert反向颜色
●自己上传线稿时，如果线稿是白色背景黑色线条，则需要选择invert预处理器
●处理器选择lineart
9.2canny边缘检测
●提取参考图中的边缘，能生成同样构图的画面，可自由决定细节，锁定细节
●如果参考图中有背景，主体比较容易被其他背景影响
9.3depth深度检测
●擅长捕捉画面中的空间关系，可生成同样构图的深度结构的图
●越近的物体会以越白的形式出现，越远的则越黑
9.4inpaint局部重绘
●和以图生图的图片重绘类似，但是会对整个画面进行重绘
9.5lineart线稿
●可以提取照片和插画的线稿，生成的图片比canny更加还原细节
9.6M-L SD线段识别
●直线捕捉，善于理解空间透视，适用于建筑和机械
●与depth相比可以有效去除建筑以外的物体
9.7softedge软边缘
●和canny类似，canny边缘更加硬朗。HED检测出的线条更像手绘，可以保留更多柔和的边缘细节
9.8tile色块重绘
●可以根据画面颜色理解画面内容，对画面进行重绘。
●可以用于将模糊图片放大和色稿细化
9.9scribble涂鸦
●从参考图中提取黑白稿，然后生成新图
●可以上传或者自己在ControlNet中画一些涂鸦，让AI帮你细化
●1girl,full body,barn lantern
9.10 normal法线
●还原图片中表面的凹凸起伏，擅长理解空间立体结构
●Bae包含远景，midas只识别近景，可调节识别阈值
9.11openpose姿势识别
●可提取参考图中的人物动作，生成骨骼图。可控制多人人物动作
9.12 Seg语义分割
●把参考图中的元素进行类别拆分，用颜色标注物体的颜色
9.13shuffle洗牌
●可以提取原图中的风格和元素进行生成

10.Midjourney是什么？
《Midjourney》是一款2022年3月面世的AI绘画工具，创始人是David Holz。只要输入想到的文字，就能通过人工智能产出相对应的图片，耗时只有大约一分钟。推出beta版后，这款搭载在Discord社区上的工具迅速成为讨论焦点。

11.提示词规则
![image](https://github.com/WeThinkIn/Interview-for-Algorithm-Engineer/assets/171827073/8bc3508b-f2bf-4366-8695-48e9fa93b21f)
