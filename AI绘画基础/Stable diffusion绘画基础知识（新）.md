# Stable Diffusion 绘画基础知识

## 1. Stable Diffusion 是什么
Stable Diffusion 是 2022 年发布的深度学习文本到图像生成模型。它主要用于根据文本的描述产生详细图像，尽管它也可以应用于其他任务，如内补绘制、外补绘制，以及在提示词指导下产生图生图的转变。

它是一种潜在扩散模型，由慕尼黑大学的 CompVis 研究团体开发的各种生成性人工神经网络之一。它是由初创公司 StabilityAI、CompVis 与 Runway 合作开发，并得到 EleutherAI 和 LAION 的支持。截至 2022 年 10 月，StabilityAI 筹集了 1.01 亿美元的资金。

Stable Diffusion 的源代码和模型权重已分别公开发布在 GitHub 和 Hugging Face，可以在大多数配备有适度 GPU 的电脑硬件上运行。而以前的专有文生图模型（如 DALL-E 和 Midjourney）只能通过云计算服务访问。

## 2. 模型分类
### 2.1 主模型（Checkpoint）
- 主模型（大模型）是 AI 绘画的基础，影响画面的整体风格。
- 主模型通常较大，一般有几 GB 到十几 GB。

### 2.2 文本嵌入（Embedding）
- Embedding 是指将自然语言文本（如句子或段落）转换为计算机可以理解的数值向量的过程。我们可以理解为打包了很多提示词进一个词。
- Embedding 的大小为几十 KB。
- Embedding 倾向于训练角色特征。

### 2.3 LoRA（Low-Rank Adaptation of Large Language Models）
- LoRA 是一种用于微调大模型的技术。LoRA 模型应用于修改图片局部或优化图片。
- LoRA 模型的大小通常为几百 MB。

### 2.4 超网络（Hypernetwork）
- Hypernetwork 用法和功能和 Embedding 类似，更适合训练风格，而不是特定具象的物体。
- Hypernetwork 的大小为几十 KB。

### 2.5 VAE
- 使用 VAE 可以优化画面颜色，有些 VAE 也会对画风产生影响。

## 3. 常见问题
### 3.1 网址打不开?
在维护/需要魔法。

### 3.2 安装目录找不到?
在桌面右键启动器——查看安装目录。

### 3.3 安装后找不到模型?
安装后需要手动刷新模型列表。

### 3.4 下载模型后画出来的图不好看?
1. 是否有触发词。
2. 是不是底模和 VAE 不一致。
3. 检查参数是否正确。

### 3.5 下载模型需要预留多少空间?
一个大模型在 3-8 GB，至少需要预留 50 GB 的空间。

## 4. ControlNet 
### 4.1 作用
让生成结果更可控。能够提取参考图中的重要信息，以一定权重影响生成图效果，可以用来控制角色动作、样貌、所处空间等等。

### 4.2 安装
- 在 StableDiffusion\extensions 中删除 controlnet 文件夹。
- 扩展 - 可下载 - 加载扩展列表 - 'ctrl+f' 在输入框里输入 ControlNet - 点击 install - 安装完成后返回已安装 - 点击应用更改并重载前端。

## 5. 提示词公式
- 质量词放在最前面。
- 其他元素根据重要性由前向后排列。
- 相关性比较高的词放在一起。
- 光照、镜头、风格、描述等。

## 6. 功能详解
### 6.1 采样迭代步数
决定图片细节质量，迭代步数越多，越详细，同时对显卡内存的消耗越大，建议数值在（20-30）。

### 6.2 提示词相关性
表示生成图像与你提示词的关联程度，常用数值在（7、 9、12）。

### 6.3 高清修复
用来放大你生成图片的分辨率，如果直接生成高分辨率图片，显存会溢出报错。
- 放大算法：重绘幅度高选择潜变量，重绘幅度低选择 R-ESRGAN 4x+ 或者 SwinIR 4x。
- 高清修复采样次数：对画面影响有限，建议数值在（0-30）。
- 重绘幅度：越高画面对比越强，也会与直接生成的图相差更远，常用数值 0.3~0.7。
- 放大倍率：等比例成倍放大图片；也可以指定放大的宽高数值。

### 6.4 生成批次和每批数量
- 生成批次：表示同样的配置让 AI 跑几次。
- 每批数量：表示 AI 每跑一次生成几张图，建议默认 1，多张图占用显存过多。

## 7. 采样是什么
SD 生成图像，会先生成一个完全随机的噪声，通过噪声预测估算图像噪声，再通过噪声预测进行去噪。去噪过程不断重复，最后得到一张干净的图像，去噪的过程称为采样，采样中使用的方法称为采样器或采样方法。

### 类型和特点
#### 老式 ODE 采样器
- Euler - 比较稳定。
- Heun - 会花费 Euler 双倍的时间。
- LMS
- PLMS 
- 50 步与 100 步的词结果差不多，高步数可能会更精细一些。

#### 祖先采样器
ccEuler a、DPM2 a、DPM+、+2S a、DPM++2S a、Karras、DPM++SDE、DPM++SDE Karras
- 一般带有字母 a 或 SDE 的采样器都是这一类，这类采样器每一步采样都会向图片添加新的噪声。如果想要稳定细化的图片就不要用祖先采样器。

#### Karras
- 带有 Karras 标签的采样器生成效果往往更好。

#### DPM/DPM++
- 效果：带++ 的 > 带2 的 > DPM。
- DPM adaptive：自适应步数，设定的步数会失效。

#### DDIM/PLMS
- SD 原始自带的采样器。
- DDIM 与祖先采样器一样，每一步采样都会向图片添加新的噪声。

#### Unipc
- 新发布的采样器，出图比较稳定，一般在 5-10 步就有不错的结果。
- 如果不能使用：设置 - 采样器参数 - Unipc 变体改为 bh2 - 保存设置 - 重启 WebUI。
- 如果列表没有这个采样器需在启动器 - 版本管理 - 选择最新的稳定版安装。

## 8. 权重控制规则
- 越靠前的关键词权重越大，() 为增加权重，[] 为减权重。
- 通常不会叠加高于三个括号。
- (tag) 提高权重 1.1 倍。
- ((tag)) 提高权重 1.21 倍，计算方式 1.1 * 1.1。
- [tag] 减少权重 1.1 倍。
- (tag:1.2) ≈ ((tag))。
- (tag:0.9) = [tag]。
- 快捷键为 ctrl + 上下箭头。

## 9. ControlNet 常见类型
### 9.1 invert 反向颜色
- 自己上传线稿时，如果线稿是白色背景黑色线条，则需要选择 invert 预处理器。
- 处理器选择 lineart。

### 9.2 canny 边缘检测
- 提取参考图中的边缘，能生成同样构图的画面，可自由决定细节，锁定细节。
- 如果参考图中有背景，主体比较容易被其他背景影响。

### 9.3 depth 深度检测
- 擅长捕捉画面中的空间关系，可生成同样构图的深度结构的图。
- 越近的物体会以越白的形式出现，越远的则越黑。

### 9.4 inpaint 局部重绘
- 和以图生图的图片重绘类似，但是会对整个画面进行重绘。

### 9.5 lineart 线稿
- 可以提取照片和插画的线稿，生成的图片比 canny 更加还原细节。

### 9.6 M-LSD 线段识别
- 直线捕捉，善于理解空间透视，适用于建筑和机械。
- 与 depth 相比可以有效去除建筑以外的物体。

### 9.7 softedge 软边缘
- 和 canny 类似，canny 边缘更加硬朗。HED 检测出的线条更像手绘，可以保留更多柔和的边缘细节。

### 9.8 tile 色块重绘
- 可以根据画面颜色理解画面内容，对画面进行重绘。
- 可以用于将模糊图片放大和色稿细化。

### 9.9 scribble 涂鸦
- 从参考图中提取黑白稿，然后生成新图。
- 可以上传或者自己在 ControlNet 中画一些涂鸦，让 AI 帮你细化。
- 示例：1 girl, full body, barn lantern。

### 9.10 normal 法线
- 还原图片中表面的凹凸起伏，擅长理解空间立体结构。
- Bae 包含远景，midas 只识别近景，可调节识别阈值。

### 9.11 openpose 姿势识别
- 可提取参考图中的人物动作，生成骨骼图。可控制多人人物动作。

### 9.12 seg 语义分割
- 把参考图中的元素进行类别拆分，用颜色标注物体的颜色。

### 9.13 shuffle 洗牌
- 可以提取原图中的风格和元素进行生成。

## 10. Midjourney 是什么？
《Midjourney》是一款 2022 年 3 月面世的 AI 绘画工具，创始人是 David Holz。只要输入想到的文字，就能通过人工智能产出相对应的图片，耗时只有大约一分钟。推出 beta 版后，这款搭载在 Discord 社区上的工具迅速成为讨论焦点。

## 11. 提示词规则
### 类别
#### 模型/风格切换
- `--v` 1~5：切换为相应的 Midjourney 模型，不推荐早期模型 1/2/3。
- `--niji` 留空，5：切换为相应的 Nijijourney 模型。
- `--style` 4a/4b/4c：切换为 4a/4b/4c 风格，Midjourney V4 模型下才能生效，不推荐使用。
- `--style` expressive/cute/scenic：切换为相应的风格，Nijijourney5 模型下才能生效。
- `--hd/test/testp` 留空：切换为相应的模型，早期模型 hd 和测试模型 test/testp，不推荐使用。

## 12. Midjourney 的应用领域是什么？
Midjourney 是一个基于人工智能的图像生成工具，广泛应用于多个领域。以下是一些主要应用领域：

### 艺术与设计
- 概念艺术：用于创作新颖的概念艺术，帮助艺术家和设计师在项目早期阶段进行视觉探索。
- 平面设计：生成独特的图像和图形元素，供平面设计师使用在广告、海报、封面等作品中。
- 动画与游戏设计：为动画和游戏项目提供角色设计、场景设定和其他视觉素材。

### 广告与营销
- 品牌宣传：创建引人注目的广告图像和品牌视觉元素。
- 社交媒体内容：生成高质量的社交媒体图片，提高品牌在数字平台上的影响力。

### 出版与媒体
- 书籍插图：为书籍、杂志和其他出版物提供插图。
- 新闻报道：为新闻文章生成相关的视觉内容，提高读者的参与度。

### 教育与科研
- 教育材料：制作教育内容的图示和插图，增强学习体验。
- 科研项目：为科学研究和学术论文生成图表和可视化图像，帮助解释复杂的概念。

### 娱乐与文化
- 影视制作：为电影和电视项目创建故事板、场景设定和概念艺术。
- 文学创作：为小说和故事提供视觉支持，帮助作者构建故事世界。

### 产品开发
- 工业设计：辅助产品设计和原型开发，生成产品概念图。
- 用户界面设计：为软件和应用程序设计用户界面元素。

通过以上这些应用领域，Midjourney 帮助各行各业的专业人士提升创作效率和作品质量。

## 13. 提示词规则有哪些？
### 类别
#### 模型/风格切换
- `--v` 1~5：切换为相应的 Midjourney 模型，不推荐早期模型 1/2/3。
- `--niji` 留空，5：切换为相应的 Nijijourney 模型。
- `--style` 4a/4b/4c：切换为 4a/4b/4c 风格，Midjourney V4 模型下才能生效，不推荐使用。
- `--style` expressive/cute/scenic：切换为相应的风格，Nijijourney5 模型下才能生效。
- `--hd/test/testp` 留空：切换为相应的模型，早期模型 hd 和测试模型 test/testp，不推荐使用。

## 14. Midjourney 的界面有哪些？
成功登录 Midjourney 后你将被引导至应用的主界面。这个界面通常包括几个核心区域：

### 画布区域
这是你进行绘画创作的主要区域，你可以在这里使用画笔工具绘制图像。

### 工具栏
工具栏通常位于界面的一侧或顶部，包含各种绘画工具和选项，如不同类型的画笔、颜色选择器、图层管理等。

### 图层管理
图层管理功能通常位于界面的底部或侧边，用于管理绘画中的不同元素的叠加顺序和可见性。

熟悉界面布局是入门的第一步。花些时间探索各个区域的功能和位置，确保你理解每个部分在绘画过程中的作用。

## 15. Midjourney 如何优化三视图效果？
三视图不完整这种情况，很大原因是因为图像的宽度不够导致的，虽然在提示词内有强调三视图，但由于画面宽度有限，MJ 很难在这么窄的画面内渲染出 3 个完整且独立的形象，所以只能少渲染一个，或者改变角度。

对应的解决方法很简单，只需要添加 `--ar` 参数，将画幅设置为横向，有了足够空间，三视图的效果立刻会得到改善。

不过画幅并不是越宽越好，比如设置成 `--ar 16:9` 的时候，图像生成的效果又会开始下降。经过测试对比，画幅比在 `7:5` 或者 `14:9` 时三视图效果最稳定。

另外建议一组参数至少生成 3 次，确定了稳定的出图效果后，再决定要不要换另一组参数。

## 16. Midjourney 生成的图像为何有边框？
这种情况同样是宽高比设置不当引起的，Midjourney 在生成一张图像时会受其“类型普遍性”的影响。我们只需要在原来的提示词后面，加上 `--ar 3:4` 参数修改宽高比，白边的情况就会消失。

## 17. Midjourney 提示词优化思路是什么？
### 提示词优化思路
1. 在 Midjourney 中越靠前的提示词权重越高，所以关于画面主体的描述要靠前，风格材质等描述次之，环境背景等靠后，以保证重点内容能被准确呈现。
2. Midjourney 中 `--s` 参数的数值越高，生成的图像细节就越丰富，质感也越明显。`--s` 默认值是 100，可以为画面增加一定的细节和美感。

## 18. 如何引导 MidJourney 创建更接近真实生活照片的图像？
通过在提示中添加以下术语：
- selfie
- 自拍
- Phone photo
- 手机照片
- Everyday photo
- 日常照片
- Low-quality photo
- 低质量照片
- Average-looking person
- 长相一般的人
- Photo posted on Facebook / Reddit
- 照片发布在 Facebook / Reddit 上

## 19. Midjourney 控图技巧有哪些？
### 控图技巧
1. **垫图**：垫图指的是你给 Midjourney 一张图，Midjourney 解析出来这张图的特点，写上咒语，Midjourney 会在这个图的特点之上，实现你的咒语内容。
2. `--iw` 图片权重参数：`iw` 后缀的使用范围是 1-2，数字越大，生成的图与垫图越相似，比如 `--iw 0.5`，`--iw` 后缀词的使用，可以很大程度提高垫图风格的准确性。
3. `--seed` 值：`seed` 值相当于 MJ 给每张图的身份证号，为了在同一张图片的基础上去做调整，可以加上 `seed` 值，提高图片的稳定性。
4. `::` 提示词权重：把 `::` 放在需要加重的关键词后，Midjourney 会加大该关键词的权重，并且关键词越靠前，权重越大。
